import streamlit as st
from openai import OpenAI, DefaultHttpxClient

st.set_page_config(page_title="Team Demo Chat", layout="centered")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®šï¼ˆæ¥ç¶šæƒ…å ±å…¥åŠ›ï¼‰ ---
with st.sidebar:
    st.header("ğŸ”Œ æ¥ç¶šè¨­å®š")
    
    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç¢ºèª
    entered_password = st.text_input("Team Password", type="password")
    # secretsãŒæœªè¨­å®šã®å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ 
    team_password = st.secrets.get("auth", {}).get("team_password", "demo")
    is_authenticated = entered_password == team_password
    
    if not is_authenticated:
        st.warning("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        st.success("èªè¨¼OK")
    
    # ngrok URLã®å…¥åŠ›
    ngrok_url = st.text_input(
        "ngrok URL (https://...)", 
        placeholder="https://xxxx-xxxx.ngrok-free.app",
        disabled=not is_authenticated
    )
    
    if st.button("æ¥ç¶šãƒ†ã‚¹ãƒˆ & ãƒªã‚»ãƒƒãƒˆ", disabled=not is_authenticated):
        st.session_state.messages = [] 
        st.rerun()

# --- ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆç”»é¢ ---
st.title("ğŸ¤– æŠ€è¡“ãƒ‡ãƒ¢ç”¨ãƒãƒ£ãƒƒãƒˆ")

if not is_authenticated or not ngrok_url:
    st.info("ğŸ‘ˆ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¨ngrokã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆngrokè­¦å‘Šå›é¿ãƒ˜ãƒƒãƒ€ãƒ¼ä»˜ãï¼‰
try:
    base_url = ngrok_url.rstrip("/") + "/v1"
    
    client = OpenAI(
        base_url=base_url,
        api_key="lm-studio",
        http_client=DefaultHttpxClient(
            headers={"ngrok-skip-browser-warning": "true"}
        )
    )
except Exception as e:
    st.error(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# å…¥åŠ›ã¨å¿œç­”
if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        full_response = ""
        
        try:
            # ãƒ¢ãƒ‡ãƒ«åã¯LM Studioå´ã§ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ãŒä½¿ã‚ã‚Œã‚‹ãŸã‚é©å½“ãªæ–‡å­—åˆ—ã§OK
            stream = client.chat.completions.create(
                model="local-model", 
                messages=[
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ],
                stream=True,
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    response_placeholder.markdown(full_response + "â–Œ")
            
            response_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            response_placeholder.markdown("ğŸš¨ **Connection Error**")
            st.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
            st.info("ğŸ’¡ ngrokã®URLãŒæ­£ã—ã„ã‹ã€PCã§LM Studioã®ã‚µãƒ¼ãƒãƒ¼ãŒONã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")