import sys
import io
import os

# --- ã€é‡è¦ã€‘Streamlit Cloudç”¨ SQLiteå¯¾ç­– ---
# Streamlit Cloudã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆSQLiteã¯å¤ã„ãŸã‚ã€pysqlite3ã‚’ä½¿ã£ã¦æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ç½®ãæ›ãˆã¾ã™
try:
    __import__('pysqlite3')
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒãªã©pysqlite3ãŒãªã„å ´åˆã¯ä½•ã‚‚ã—ãªã„
# -------------------------------------------

import pandas as pd
import streamlit as st
from typing import Annotated, TypedDict

# LangGraph & LangChain Imports
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.graph.message import add_messages
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
import httpx # ngrokãƒ˜ãƒƒãƒ€ãƒ¼ç”¨

# RAGç”¨ Imports
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

# -----------------------------------------------------------------
# â–¼ è¨­å®šãƒ»å®šæ•°
# -----------------------------------------------------------------
st.set_page_config(page_title="Legal Analysis Chatbot", layout="wide")
st.title("ğŸ¤– è¦ªæ¨©å–ªå¤±ãƒ»åœæ­¢äº‹ä¾‹è¡¨åˆ†æãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ (Team Demo)")

st.markdown("""
äº‹ä¾‹è¡¨ã®æ¤œç´¢ã‚’ã—ã¦ãã‚Œã¾ã™ã€‚äº‹ä¾‹ç•ªå·ã¯ã€1æ¡ã®case_idã«å¤‰æ›ã—ã¾ã—ãŸã€‚1æ¡ç›®ãŒ1ã®ã‚‚ã®ãŒè¦ªæ¨©å–ªå¤±ã€2ã®ã‚‚ã®ãŒè¦ªæ¨©åœæ­¢ã§ã€æ®‹ã‚Š3æ¡ã¯ã€ã‚‚ã¨ã‚‚ã¨ã®äº‹ä¾‹ç•ªå·ã‹ã‚‰ãƒã‚¤ãƒ•ãƒ³ã‚’é™¤ã„ãŸã‚‚ã®ã§ã™ã€‚
ä¾‹ï¼šè¦ªæ¨©å–ªå¤±ã®3-1->1031ã€è¦ªæ¨©åœæ­¢ã®20->2200
""")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.header("ğŸ” æ¥ç¶šè¨­å®š")
    
    # 1. ãƒãƒ¼ãƒ èªè¨¼ (ç°¡æ˜“ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰)
    team_password = st.secrets.get("auth", {}).get("team_password", "demo1234")
    input_password = st.text_input("Team Password", type="password")
    is_authenticated = input_password == team_password

    if is_authenticated:
        st.success("èªè¨¼OK")
    else:
        st.warning("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    # 2. ngrok URLå…¥åŠ› (æ¯å›å¤‰ã‚ã‚‹ãŸã‚æ‰‹å‹•å…¥åŠ›)
    st.markdown("---")
    st.write("ğŸ”— **LLMæ¥ç¶š (ngrok)**")
    ngrok_url = st.text_input(
        "ngrok URL", 
        placeholder="https://xxxx.ngrok-free.app",
        disabled=not is_authenticated,
        help="ãƒ­ãƒ¼ã‚«ãƒ«PCã§ç™ºè¡Œã•ã‚ŒãŸngrokã®HTTPS URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    )
    
    # ãƒ¢ãƒ‡ãƒ«åã¯å›ºå®šã¾ãŸã¯å…¥åŠ›
    model_name = "local-model"

    st.markdown("---")
    st.write("ğŸ“‚ **ãƒ‡ãƒ¼ã‚¿è¨­å®š**")
    # CSVã¯ãƒªãƒã‚¸ãƒˆãƒªåŒæ¢±ã‚’åŸºæœ¬ã¨ã™ã‚‹ãŒã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚‚è¨±å¯
    uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ã (ä»»æ„)", type=["csv"])
    
    # DBãƒ‘ã‚¹: Streamlit Cloudã®ãƒ‘ã‚¹æ§‹æˆã«åˆã‚ã›ã¦ç›¸å¯¾ãƒ‘ã‚¹æŒ‡å®š
    # ãƒªãƒã‚¸ãƒˆãƒªç›´ä¸‹ã« 'DB' ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚‹å‰æ
    db_refs_path = st.text_input("å‚è€ƒæ–‡çŒ®DBãƒ‘ã‚¹", value="./DB")

# -----------------------------------------------------------------
# â–¼ 1. ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰
# -----------------------------------------------------------------
@st.cache_data
def load_data(file_or_path) -> pd.DataFrame:
    try:
        return pd.read_csv(file_or_path)
    except Exception as e:
        return pd.DataFrame()

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ­ã‚¸ãƒƒã‚¯
df_global = pd.DataFrame()

if uploaded_file is not None:
    df_global = load_data(uploaded_file)
    st.sidebar.success(f"Uploadãƒ‡ãƒ¼ã‚¿ä½¿ç”¨: {len(df_global)}ä»¶")
else:
    # ãƒªãƒã‚¸ãƒˆãƒªå†…ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆCSVã‚’æ¢ã™
    default_csv = "Cases_list_integrated.csv"
    if os.path.exists(default_csv):
        df_global = load_data(default_csv)
        st.sidebar.info(f"ãƒªãƒã‚¸ãƒˆãƒªå†…ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨: {len(df_global)}ä»¶")
    else:
        st.sidebar.warning("CSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

# -----------------------------------------------------------------
# â–¼ 2. ãƒ„ãƒ¼ãƒ«å®šç¾©
# -----------------------------------------------------------------
# LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (ngrokãƒ˜ãƒƒãƒ€ãƒ¼å¯¾å¿œ)
def get_llm_client(base_url, api_key="lm-studio"):
    custom_client = httpx.Client(headers={"ngrok-skip-browser-warning": "true"})
    return ChatOpenAI(
        base_url=base_url,
        api_key=api_key,
        model=model_name,
        temperature=0.0,
        http_client=custom_client
    )

@tool
def get_case_details(case_id: str) -> str:
    """å˜ä¸€ã® case_id ã‚’å—ã‘å–ã‚Šã€CSVã‹ã‚‰ãã®äº‹æ¡ˆã®è©³ç´°ã‚’å–å¾—ã—ã¾ã™ã€‚"""
    if df_global.empty: return "ãƒ‡ãƒ¼ã‚¿ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    try:
        # IDã®å‹æºã‚‰ãå¸å
        try:
            target_id = int(case_id.strip())
            record = df_global[df_global['case_id'] == target_id]
        except:
            target_id = case_id.strip()
            record = df_global[df_global['case_id'].astype(str) == target_id]

        if record.empty:
            return f"case_id '{case_id}' ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            
        row = record.iloc[0]
        details = [f"--- case_id: {row['case_id']} ã®è©³ç´° ---"]
        for col, val in row.items():
            if pd.notna(val) and str(val).strip() != "":
                details.append(f"  - {col}: {val}")
        return "\n".join(details)
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: {e}"

@tool
def analyze_statistics(query: str) -> str:
    """
    ã€é‡è¦ã€‘çµ±è¨ˆåˆ†æã ã‘ã§ãªãã€ã€Œæ¡ä»¶ã«åˆã†äº‹æ¡ˆã®æ¤œç´¢ã€ã«ã‚‚ä½¿ç”¨ã—ã¾ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…·ä½“çš„ãª case_id ã‚’æŒ‡å®šã›ãšã€ã€Œã€œãªäº‹æ¡ˆã«ã¤ã„ã¦æ•™ãˆã¦ã€ã€Œæ¤œå¯Ÿå®˜ã®ç”³ç«‹ã¦ã¯ï¼Ÿã€ã®ã‚ˆã†ã«è³ªå•ã—ãŸå ´åˆã€
    å¿…ãšã“ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ Pandas ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã€è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã‚„è¦ç´„ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
    """
    # ... (ä»¥ä¸‹ã®ä¸­èº«ã®ã‚³ãƒ¼ãƒ‰ã¯å¤‰æ›´ãªã—) ...
    # ngrokçµŒç”±ã§Codeç”Ÿæˆç”¨LLMã‚’å‘¼ã¶
    if not ngrok_url:
        return "ã‚¨ãƒ©ãƒ¼: ngrok URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    
    base_url_v1 = ngrok_url.rstrip("/") + "/v1"
    coder_llm = get_llm_client(base_url_v1)

    columns_list = ", ".join(df_global.columns.tolist()) if not df_global.empty else "ãªã—"
    
    # ---------------------------------------------------------
    # â–¼ åˆ—åã®å®šç¾©è¾æ›¸ (ã”æç¤ºã®CSVå®šç¾©ã«åˆã‚ã›ã¦ä½œæˆ)
    # ---------------------------------------------------------
    column_mapping_prompt = """
    ã€é‡è¦: åˆ—åã®å®šç¾©è¾æ›¸ (æ—¥æœ¬èªã®è³ªå• -> å¤‰æ•°å)ã€‘
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å«ã¾ã‚Œã‚‹å˜èªã¯ã€ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦åˆ—åã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚

    1. äº‹æ¡ˆã®åŸºæœ¬æƒ…å ±
       - ã€Œäº‹ä¾‹IDã€ã€ŒIDã€ -> 'case_id'
       - ã€Œè£åˆ¤æ‰€ã€ -> 'court_type'
       - ã€Œå¯©åˆ¤æ—¥ã€ã€Œæ—¥ä»˜ã€ -> 'decision_date' (å½¢å¼: YYYY-MM-DD)
       - ã€Œç”³ç«‹å†…å®¹ã€ã€Œç”³ç«‹ã¦ã®ç¨®é¡ã€ -> 'petition_type'
          â€»ã€Œè¦ªæ¨©åœæ­¢ã€,ã€Œè¦ªæ¨©å–ªå¤±ã€,ã€Œè¦ªæ¨©åœæ­¢å–æ¶ˆã—ã€ã®ã„ãšã‚Œã‹ã§ã€ä»–ã«å…¥ã‚‹ã‚‚ã®ã¯ãªã„ã€‚å‹æ‰‹ã«ä½œã‚‰ãªã„ã“ã¨
       - ã€Œè™å¾…ã€ã€Œè™å¾…ã®é¡å‹ã€ -> 'abuse_type_1', 'abuse_type_2, ...'


    2. å½“äº‹è€… (ã‚¿ã‚°æƒ…å ±)
       - ã€Œç”³ç«‹äººã€ -> 'petitioner_A_tag', 'petitioner_B_tag' (äººæ•°ã¯ 'petitioner_count')
       - ã€Œäº‹ä»¶æœ¬äººã€ã€Œç›¸æ‰‹æ–¹ã€ã€Œè¦ªã€ -> 'subject_A_tag', 'subject_B_tag' (äººæ•°ã¯ 'subject_count')
          â€» [çˆ¶], [æ¯], [æ¤œå¯Ÿå®˜], [å…ç«¥ç›¸è«‡æ‰€é•·] ãªã©ãŒå«ã¾ã‚Œã‚‹ã€‚ã€Œæœªæˆå¹´è€…æœ¬äººã€ã¨ã¯ã€[å­]ã®ã“ã¨ã‚’æŒ‡ã™ã€‚

    3. å­ã©ã‚‚ã®æƒ…å ± (é‡è¦: æœ€å¤§4äººã¾ã§åˆ—ãŒæ¨ªã«å±•é–‹ã•ã‚Œã¦ã„ã¾ã™)
       - ã€Œå­ã®ä»£ç†äººã®æœ‰ç„¡ã€ -> 'child_counsel'
          â€»ã“ã®åˆ—ãŒTrueã§ãªã‘ã‚Œã°ã€ã€Œå­ã€åˆã¯ã€Œæœªæˆå¹´è€…ã€ã«ä»£ç†äººã¯ã¤ã„ã¦ã„ãªã‹ã£ãŸã“ã¨ã«ãªã‚‹ã€‚
       - ã€Œå­ã®äººæ•°ã€ -> 'child_count'
       - ã€Œå­ã€ã€Œå­ä¾›ã€ -> 'child_A_tag', 'child_B_tag', 'child_C_tag', 'child_D_tag'
       - ã€Œå¹´é½¢ã€ -> 'child_A_age', 'child_B_age', 'child_C_age', 'child_D_age'
       - ã€Œç›£è­·çŠ¶æ³ã€ -> 'child_A_custody', 'child_B_custody', 'child_C_custody', 'child_D_custody'


    4. å¯©åˆ¤çµæœ (æœ€ã‚‚é‡è¦)
       - ã€Œçµæœã€ã€Œå¯©åˆ¤ã€ -> 'child_A_result', 'child_B_result', 'child_C_result', 'child_D_result'      
       - ã€Œåœæ­¢æœŸé–“ã€ã€Œæœˆæ•°ã€ -> 'child_A_suspension_months', ... (æ•°å€¤)
       - ã€Œåœæ­¢çµ‚äº†æ—¥ã€ -> 'child_A_suspension_end_date', ...

    ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆæ™‚ã®ç‰¹åˆ¥ãƒ«ãƒ¼ãƒ«ã€‘
    ãƒ«ãƒ¼ãƒ«1 (è¤‡æ•°åˆ—ã®æ¤œç´¢):
      ã€ŒçµæœãŒè¦ªæ¨©å–ªå¤±ã®äº‹æ¡ˆã€ã®ã‚ˆã†ã«æ¤œç´¢ã™ã‚‹å ´åˆã€å¯¾è±¡ã¯å­ä¾›ã”ã¨ã«åˆ†ã‹ã‚Œã¦ã„ã¾ã™ã€‚
      å¿…ãš `child_A_result`, `child_B_result`, `child_C_result`, `child_D_result`ã®ã„ãšã‚Œã‹ãŒæ¡ä»¶ã‚’æº€ãŸã™ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚
      (ä¾‹: `df[(df['child_A_result'] == 'è¦ªæ¨©å–ªå¤±') | (df['child_B_result'] == 'è¦ªæ¨©å–ªå¤±')]`)

    ãƒ«ãƒ¼ãƒ«2 (ç‰¹å®šã®å­ã®æŒ‡å®š):
      ã€Œç¬¬1å­ã€ã‚„ã€Œé•·ç”·ãƒ»é•·å¥³ã€ç­‰ã®æŒ‡å®šãŒãªã„é™ã‚Šã€åŸºæœ¬çš„ã«ã¯ 'child_A_...' (ç¬¬1å­) ã‚’ä¸»ã¨ã—ã¦åˆ†æã—ã¦ãã ã•ã„ã€‚
      ãŸã ã—ã€Œå…¨ä½“ã€ã‚„ã€Œä»¶æ•°ã€ã‚’èã‹ã‚ŒãŸå ´åˆã¯ã€äº‹æ¡ˆå˜ä½(`case_id`)ã§ã‚«ã‚¦ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚
    """

    # 4. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰ (ä»¥å‰ã¨åŒã˜æ§‹æˆã«ã€ä¸Šè¨˜ã®è¾æ›¸ã‚’åŸ‹ã‚è¾¼ã¿)
    prompt = f"""
    ã‚ãªãŸã¯å„ªç§€ãªPythonãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã® Pandas ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚
    
    ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã€‘
    å¤‰æ•°å: df
    å…¨ã¦ã®åˆ—å: {columns_list}
    
    {column_mapping_prompt}
    
    ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
    {query}
    
    ã€å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã€‘
    - ä¸Šè¨˜ã®è¾æ›¸ã«ã‚ã‚‹åˆ—åã‚’æ­£ç¢ºã«ä½¿ç”¨ã™ã‚‹ã“ã¨ã€‚å­˜åœ¨ã—ãªã„åˆ—å(ä¾‹: 'judgment', 'result_all')ã¯ç¦æ­¢ã€‚
    - Pythonã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’å‡ºåŠ› (Markdownã‚¿ã‚°ãªã—)ã€‚
    - çµæœã¯å¿…ãš `print()` ã§å‡ºåŠ›ã€‚
    """


    try:
        response = coder_llm.invoke(prompt)
        code = response.content.replace("```python", "").replace("```", "").strip()
        
        local_env = {'df': df_global.copy(), 'pd': pd}
        old_stdout = sys.stdout
        redirected_output = io.StringIO()
        sys.stdout = redirected_output
        
        try:
            exec(code, {}, local_env)
            result = redirected_output.getvalue()
        except Exception as e:
            result = f"ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"
        finally:
            sys.stdout = old_stdout
            
        return f"ã€åˆ†æçµæœã€‘\n{result}" if result.strip() else "çµæœãªã—"

    except Exception as e:
        return f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}"

# -----------------------------------------------------------------
# â–¼ 3. RAGæ©Ÿèƒ½ (å‚è€ƒæ–‡çŒ®æ¤œç´¢)
# -----------------------------------------------------------------
@st.cache_resource(show_spinner="å‚è€ƒæ–‡çŒ®DBã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
def get_ref_retriever(db_path):
    """
    Streamlit Cloudä¸Šã§HuggingFaceãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€Chromaã‚’èª­ã¿è¾¼ã‚€ã€‚
    æ³¨æ„: åˆå›ã¯ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰(æ•°GB)ãŒèµ°ã‚‹ãŸã‚æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚
    """
    try:
        if not os.path.exists(db_path):
            return None
            
        # ãƒ¢ãƒ‡ãƒ«è¨­å®š (CPUå‹•ä½œ)
        model_kwargs = {'device': 'cpu'}
        encode_kwargs = {'normalize_embeddings': False}
        embedding_model_name = "intfloat/multilingual-e5-large"
        
        embeddings = HuggingFaceEmbeddings(
            model_name=embedding_model_name,
            model_kwargs=model_kwargs,
            encode_kwargs=encode_kwargs
        )
        
        db_refs = Chroma(persist_directory=db_path, embedding_function=embeddings)
        return db_refs.as_retriever(search_kwargs={"k": 3})
    except Exception as e:
        st.error(f"DBãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def search_references_action(user_query, llm_client):
    if not os.path.exists(db_refs_path):
        return "âš ï¸ ãƒªãƒã‚¸ãƒˆãƒªå†…ã« 'DB' ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"

    retriever = get_ref_retriever(db_refs_path)
    if not retriever:
        return "DBã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    
    try:
        docs = retriever.invoke(user_query)
        if not docs: return "é–¢é€£æ–‡çŒ®ãªã—"
        
        # 1. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹ç¯‰
        context_list = []
        ref_display_text = ""
        
        for i, doc in enumerate(docs, 1):
            source = doc.metadata.get("source", "ä¸æ˜")
            content = doc.page_content.replace("\n", " ")
            
            # LLMå…¥åŠ›ç”¨
            context_list.append(f"æ–‡çŒ®[{i}] (å‡ºå…¸: {source}):\n{content}")
            
            # è¡¨ç¤ºç”¨ (æŠœç²‹)
            ref_display_text += f"**[{i}] {source}**\n> {content[:300]}...\n\n"

        context_str = "\n\n".join(context_list)

        # 2. LLMã«ã‚ˆã‚‹å›ç­”ç”Ÿæˆ
        prompt = f"""
        ã‚ãªãŸã¯æ³•å¾‹ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ã€å‚è€ƒæ–‡çŒ®ã€‘ã®å†…å®¹ã®ã¿ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€è³ªå•ã€‘ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
        å›ç­”ã®éš›ã¯ã€ã©ã®æ–‡çŒ®ã‚’å‚ç…§ã—ãŸã‹ï¼ˆä¾‹: [1]ï¼‰ã‚’æ–‡ä¸­ã«æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚
        å‚è€ƒæ–‡çŒ®ã«ç­”ãˆãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ã€Œå‚è€ƒæ–‡çŒ®ã«ã¯è¨˜è¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚

        ã€å‚è€ƒæ–‡çŒ®ã€‘
        {context_str}

        ã€è³ªå•ã€‘
        {user_query}
        """
        
        response = llm_client.invoke(prompt)
        answer = response.content

        # 3. çµæœã®çµåˆ
        final_output = f"### ğŸ¤– å‚è€ƒæ–‡çŒ®ã«åŸºã¥ãå›ç­”\n{answer}\n\n---\n### ğŸ“š å‚ç…§ã•ã‚ŒãŸæ–‡çŒ®\n{ref_display_text}"
        return final_output

    except Exception as e:
        return f"æ¤œç´¢ãƒ»ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"

# -----------------------------------------------------------------
# â–¼ 4. LangGraph æ§‹ç¯‰
# -----------------------------------------------------------------
@st.cache_resource
def build_graph(_llm_client):
    # ãƒ„ãƒ¼ãƒ«ãƒªã‚¹ãƒˆ
    tools = [get_case_details, analyze_statistics]
    
    # ãƒ„ãƒ¼ãƒ«ãƒã‚¤ãƒ³ãƒ‰
    llm_with_tools = _llm_client.bind_tools(tools)

    class AgentState(TypedDict):
        messages: Annotated[list[BaseMessage], add_messages]

    def agent_node(state: AgentState):
        messages = state['messages']
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¼·åŒ–
        system_prompt = SystemMessage(content="""
        ã‚ãªãŸã¯æ³•å¾‹å°‚é–€å®¶ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
        ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚

        1. **å…·ä½“çš„ãª case_id ãŒãªã„è³ªå•ã®å ´åˆ:**
           - å³åº§ã«ã€ŒIDãŒãªã„ã€ã¨æ–­ã‚‰ãšã€å¿…ãš `analyze_statistics` ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚
           - ä¾‹: "df[df['petitioner'] == 'æ¤œå¯Ÿå®˜']" ã®ã‚ˆã†ãªã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦äº‹ä¾‹ã‚’æ¢ã—ã¾ã™ã€‚

        2. **ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿æ–¹:**
           - `petition_type` ã¯ã€Œç”³ç«‹å†…å®¹ã€ã€`child_..._result` ã¯ã€Œæœ€çµ‚åˆ¤æ–­ã€ã§ã™ã€‚
           - `result: å´ä¸‹` ã¯ã€Œç”³ç«‹ã¦ãŒèªã‚ã‚‰ã‚Œãªã‹ã£ãŸã€ã¨ã„ã†æ„å‘³ã§ã™ã€‚
        
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å½¹ã«ç«‹ã¤ã‚ˆã†ã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸå…·ä½“çš„ãªå›ç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚
        """)
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†
        if not isinstance(messages[0], SystemMessage):
            messages = [system_prompt] + messages
        else:
            messages[0] = system_prompt # æ—¢å­˜ãŒã‚ã‚Œã°ä¸Šæ›¸ã
        
        response = llm_with_tools.invoke(messages)
        return {"messages": [response]}

    tool_node = ToolNode(tools)

    workflow = StateGraph(AgentState)
    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tool_node)
    workflow.set_entry_point("agent")
    
    def should_continue(state):
        last_message = state['messages'][-1]
        if last_message.tool_calls: return "tools"
        return END

    workflow.add_conditional_edges("agent", should_continue)
    workflow.add_edge("tools", "agent")
    
    return workflow.compile()

# -----------------------------------------------------------------
# â–¼ 5. ãƒ¡ã‚¤ãƒ³å‡¦ç†
# -----------------------------------------------------------------

# èªè¨¼ & URLãƒã‚§ãƒƒã‚¯
if not is_authenticated or not ngrok_url:
    st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¨ngrok URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ã‚¢ãƒ—ãƒªåˆæœŸåŒ–
base_url_v1 = ngrok_url.rstrip("/") + "/v1"
main_llm_client = get_llm_client(base_url_v1)
app = build_graph(main_llm_client)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message.get("tool_output"):
            with st.expander("è©³ç´°ãƒ‡ãƒ¼ã‚¿"):
                st.text(message["tool_output"])

# å‚è€ƒæ–‡çŒ®ãƒœã‚¿ãƒ³
if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
    if len(st.session_state.messages) >= 2:
        last_user_query = st.session_state.messages[-2]["content"]
        if st.button("ğŸ“š å‚è€ƒæ–‡çŒ®ã‚‚æ¤œç´¢ã™ã‚‹"):
            with st.spinner("æ¤œç´¢ä¸­... (åˆå›ã¯ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)"):
                ref_result = search_references_action(last_user_query, main_llm_client)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": ref_result,
                    "tool_output": None
                })
                st.rerun()

# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    if df_global.empty:
        st.error("CSVãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        status_container = st.status("æ€è€ƒä¸­...", expanded=True)
        
        # LangGraphå®Ÿè¡Œç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¤‰æ›
        lc_messages = []
        for m in st.session_state.messages:
            role = "user" if m["role"] == "user" else "assistant"
            lc_messages.append(HumanMessage(content=m["content"]) if role == "user" else AIMessage(content=m["content"]))

        try:
            inputs = {"messages": lc_messages}
            full_response = ""
            captured_outputs = []

            for event in app.stream(inputs, stream_mode="values"):
                last_msg = event["messages"][-1]
                
                if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:
                    for tc in last_msg.tool_calls:
                        status_container.write(f"ğŸ› ï¸ {tc['name']}")
                
                elif last_msg.type == "tool":
                    captured_outputs.append(last_msg.content)
                
                elif isinstance(last_msg, AIMessage) and not last_msg.tool_calls:
                    full_response = last_msg.content
                    message_placeholder.markdown(full_response)

            status_container.update(label="å®Œäº†", state="complete", expanded=False)
            
            if full_response:
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": full_response,
                    "tool_output": "\n".join(captured_outputs) if captured_outputs else None
                })
                st.rerun()
                
        except Exception as e:
            status_container.update(label="ã‚¨ãƒ©ãƒ¼", state="error")
            st.error(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            st.info("ngrokã®URLãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")